{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d7d7846",
   "metadata": {},
   "source": [
    "## DATA LOADING AND INSPECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b6dae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f1eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "def data_loader(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a8b1944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = \"great_customers.csv\"\n",
    "data = data_loader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09e55dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id   age workclass    salary  education_rank marital-status  \\\n",
      "0  1004889  14.0   private  70773.00               9  Never-married   \n",
      "1  1012811  25.0   private  76597.00               9       Divorced   \n",
      "2  1006870  21.0   private  47947.25              10  Never-married   \n",
      "3  1022149  23.0   private  41740.25               7       Divorced   \n",
      "4  1029558  26.0   private       NaN               9        Married   \n",
      "\n",
      "  occupation           race     sex  mins_beerdrinking_year  \\\n",
      "0      sales  not_caucasian    Male                     0.0   \n",
      "1      sales      caucasian  Female                     0.0   \n",
      "2   clerical      caucasian  Female                     0.0   \n",
      "3      sales      caucasian  Female                     0.0   \n",
      "4      sales  not_caucasian    Male                     NaN   \n",
      "\n",
      "   mins_exercising_year  works_hours  tea_per_year  coffee_per_year  \\\n",
      "0                   0.0           40         399.0              NaN   \n",
      "1                   0.0           30         256.0              NaN   \n",
      "2                   0.0           10         442.0            276.0   \n",
      "3                   0.0           20           NaN              NaN   \n",
      "4                   0.0           36           NaN            120.0   \n",
      "\n",
      "   great_customer_class  \n",
      "0                     0  \n",
      "1                     0  \n",
      "2                     0  \n",
      "3                     0  \n",
      "4                     0  \n"
     ]
    }
   ],
   "source": [
    "# Inspect the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a021b8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13599 entries, 0 to 13598\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   user_id                 13599 non-null  int64  \n",
      " 1   age                     13178 non-null  float64\n",
      " 2   workclass               13056 non-null  object \n",
      " 3   salary                  13177 non-null  float64\n",
      " 4   education_rank          13599 non-null  int64  \n",
      " 5   marital-status          13599 non-null  object \n",
      " 6   occupation              13056 non-null  object \n",
      " 7   race                    13599 non-null  object \n",
      " 8   sex                     13599 non-null  object \n",
      " 9   mins_beerdrinking_year  13175 non-null  float64\n",
      " 10  mins_exercising_year    13178 non-null  float64\n",
      " 11  works_hours             13599 non-null  int64  \n",
      " 12  tea_per_year            11170 non-null  float64\n",
      " 13  coffee_per_year         11188 non-null  float64\n",
      " 14  great_customer_class    13599 non-null  int64  \n",
      "dtypes: float64(6), int64(4), object(5)\n",
      "memory usage: 1.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb5028",
   "metadata": {},
   "source": [
    "## STEP 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe16ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "def data_cleaning(data):\n",
    "    # Handle missing values (if any)\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    # Remove duplicate rows (if any)\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Check and handle outliers\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4f4e036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data cleaning\n",
    "data = data_cleaning(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc4efb6",
   "metadata": {},
   "source": [
    "## STEP 3: FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e33d9505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "def feature_selection(data):\n",
    "    # Select the relevant features\n",
    "    selected_features = data[['age', 'salary', 'education_rank', 'marital-status', 'occupation', 'sex', 'tea_per_year', 'coffee_per_year']]\n",
    "\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "# Perform feature selection\n",
    "selected_features = feature_selection(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654494a9",
   "metadata": {},
   "source": [
    "## STEP 4: PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4018a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Numpy library:\n",
    "import numpy as np\n",
    "# Preprocessing\n",
    "\n",
    "def preprocess_data(data):\n",
    "    # Handle categorical variables using one-hot encoding\n",
    "    categorical_cols = ['marital-status', 'occupation']\n",
    "    numeric_cols = ['age', 'salary', 'education_rank', 'tea_per_year', 'coffee_per_year']\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    categorical_data_encoded = encoder.fit_transform(data[categorical_cols])\n",
    "    \n",
    "    # Select only the numeric columns for imputation\n",
    "    numeric_data = data[numeric_cols]\n",
    "    \n",
    "    # Impute missing values in numeric columns\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    numeric_data_imputed = imputer.fit_transform(numeric_data)\n",
    "    \n",
    "    # Combine encoded categorical features and imputed numeric features\n",
    "    processed_data = np.concatenate([categorical_data_encoded, numeric_data_imputed], axis=1)\n",
    "    \n",
    "    return processed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "370fb608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def preprocess_data(data):\n",
    "    # Handle categorical variables using one-hot encoding\n",
    "    categorical_cols = ['marital-status', 'occupation']\n",
    "    numeric_cols = ['age', 'salary', 'education_rank', 'tea_per_year', 'coffee_per_year']\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    categorical_data_encoded = encoder.fit_transform(data[categorical_cols])\n",
    "    \n",
    "    # Select only the numeric columns for imputation\n",
    "    numeric_data = data[numeric_cols]\n",
    "    \n",
    "    # Impute missing values in numeric columns\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    numeric_data_imputed = imputer.fit_transform(numeric_data)\n",
    "    \n",
    "    # Check if any of the arrays are empty\n",
    "    if categorical_data_encoded.shape[0] == 0:\n",
    "        processed_data = numeric_data_imputed\n",
    "    elif numeric_data_imputed.shape[0] == 0:\n",
    "        processed_data = categorical_data_encoded\n",
    "    else:\n",
    "        # Combine encoded categorical features and imputed numeric features\n",
    "        processed_data = np.concatenate([categorical_data_encoded, numeric_data_imputed], axis=1)\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e3377e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KUMUD\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "processed_data = preprocess_data(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c305f360",
   "metadata": {},
   "source": [
    "## STEP 5: MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "640fcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant files for model building:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88931da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_data, data['great_customer_class'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb200794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(selected_features, data['great_customer_class'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d943dec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KUMUD\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\KUMUD\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Define a dictionary with models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Evaluate models\n",
    "model_metrics = {\n",
    "    'Model': [],\n",
    "    'Precision': [],\n",
    "    'ROC-AUC': [],\n",
    "    'Accuracy': [],\n",
    "    'F1-Score': []\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    model_metrics['Model'].append(name)\n",
    "    model_metrics['Precision'].append(precision)\n",
    "    model_metrics['ROC-AUC'].append(roc_auc)\n",
    "    model_metrics['Accuracy'].append(accuracy)\n",
    "    model_metrics['F1-Score'].append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54de33d9",
   "metadata": {},
   "source": [
    "## STEP 6: ENSEMBLE LEARNING TECHNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6f48358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KUMUD\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to model_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Apply ensemble learning (Voting)\n",
    "ensemble.fit(X_train, y_train)\n",
    "ensemble_predictions = ensemble.predict(X_test)\n",
    "ensemble_precision = precision_score(y_test, ensemble_predictions)\n",
    "ensemble_roc_auc = roc_auc_score(y_test, ensemble_predictions)\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "ensemble_f1 = f1_score(y_test, ensemble_predictions)\n",
    "\n",
    "model_metrics['Model'].append('Ensemble (Voting)')\n",
    "model_metrics['Precision'].append(ensemble_precision)\n",
    "model_metrics['ROC-AUC'].append(ensemble_roc_auc)\n",
    "model_metrics['Accuracy'].append(ensemble_accuracy)\n",
    "model_metrics['F1-Score'].append(ensemble_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99435fc4",
   "metadata": {},
   "source": [
    "## STEP 7: Metric to evaluate your prediction model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c88e659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to model_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(model_metrics)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('model_results.csv', index=False)\n",
    "print(\"Results saved to model_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd7d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
